# -*- coding: utf-8 -*-
"""Regression Task.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I9q2ElId1nxpqHt_KtJ2_d1bbCnD7gsl
"""

import matplotlib.pyplot as plt
import numpy as np
import cv2
import os
import PIL #image libary in python
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

data_dir = "/content/drive/MyDrive/archive.zip (Unzipped Files)/utkface_aligned_cropped/UTKFace"

#converting this data directory into  a pathlib
import pathlib
data_dir = pathlib.Path(data_dir)
data_dir

img_count = len(list(data_dir.glob('*.jpg')))
img_count

import os
# Example filename
filename = "26_1_0_20170117201629485.jpg.chip"
# Split the filename by underscores
filename_parts = filename.split('_')
# Extract the age (first part of the filename)
age = int(filename_parts[0])

print("Age extracted from filename:", age)

from PIL import Image
image_path = "/content/drive/MyDrive/archive.zip (Unzipped Files)/utkface_aligned_cropped/UTKFace/16_1_0_20170109204349968.jpg.chip.jpg"
image = Image.open(image_path)
image.show()
plt.imshow(image)
plt.axis('off')
plt.show()

filenames = os.listdir(data_dir)

ages = []
for filename in filenames:
    # Split the filename by underscores
    filename_parts = filename.split('_')
    # Extract the age (first part of the filename)
    age = int(filename_parts[0])
    ages.append(age)

# Load images and preprocess them
images = []
for filename in filenames:
    # Construct the full path to the image
    image_path = os.path.join(data_dir, filename)
    # Load and preprocess the image
    img = cv2.imread(image_path)
    img = cv2.resize(img, (100, 100))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = img / 255.0  # Normalize pixel values to [0, 1]

    # Append the image to the list of images
    images.append(img)

# Convert the lists to numpy arrays
images = np.array(images)
ages = np.array(ages)

print("Shape of images array:", images.shape)
print("Shape of ages array:", ages.shape)

from sklearn.model_selection import train_test_split

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(images, ages , test_size= 0.15, random_state=42)

X_train_scaled = X_train / 255
X_test_scaled = X_test / 255

len(X_train)

len(X_test)

X_train[0]

X_train_scaled[0]

from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Dropout

# Define the model architecture with batch normalization
model = Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(256, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
    layers.Dense(256, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
    layers.Dense(128, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
    layers.Dense(1)
])

# Compile the model
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Display the model summary
model.summary()

# Define the number of epochs and batch size
epochs = 40
batch_size = 32

# Train the model with validation data
history = model.fit(X_train_scaled, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test_scaled, y_test))

test_loss, test_mae = model.evaluate(X_test_scaled, y_test)

print("Test Loss:", test_loss)
print("Test MAE:", test_mae)

import matplotlib.pyplot as plt

# Get the training and validation loss values from the history object
train_loss = history.history['loss']
val_loss = history.history['val_loss']

# Get the number of epochs
epochs = range(1, len(train_loss) + 1)

# Plot the training and validation loss
plt.plot(epochs, train_loss, 'b', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()