# -*- coding: utf-8 -*-
"""Regression Task with simple CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UAWBsa8TmvKIx9mAnChZjDm0WP0UEaOY
"""

import matplotlib.pyplot as plt
import numpy as np
import cv2
import os
import PIL #image libary in python
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

data_dir = "/content/drive/MyDrive/archive.zip (Unzipped Files)/utkface_aligned_cropped/UTKFace"

#converting this data directory into  a pathlib
import pathlib
data_dir = pathlib.Path(data_dir)
data_dir

img_count = len(list(data_dir.glob('*.jpg')))
img_count

import os
# Example filename
filename = "26_1_0_20170117201629485.jpg.chip"
# Split the filename by underscores
filename_parts = filename.split('_')
# Extract the age (first part of the filename)
age = int(filename_parts[0])

print("Age extracted from filename:", age)

# Get a list of all filenames in the directory
filenames = os.listdir(data_dir)

# Extract age from each filename
ages = []
for filename in filenames:
    # Split the filename by underscores
    filename_parts = filename.split('_')
    # Extract the age (first part of the filename)
    age = int(filename_parts[0])
    ages.append(age)

print("First 10 ages extracted from filenames:")
print(ages[:10])

from PIL import Image
image_path = "/content/drive/MyDrive/archive.zip (Unzipped Files)/utkface_aligned_cropped/UTKFace/16_1_0_20170109204349968.jpg.chip.jpg"
image = Image.open(image_path)
image.show()
plt.imshow(image)
plt.axis('off')
plt.show()

input_shape = (128, 128)

# Initialize lists to store preprocessed images and corresponding labels
preprocessed_images = []
labels = []

# Iterate through the directory and preprocess each image
for filename in os.listdir(data_dir):
    # Construct the full path to the image
    image_path = os.path.join(data_dir, filename)

    # Load the image
    image = Image.open(image_path)

    # Resize the image
    image = image.resize(input_shape)

    # Convert the image to a NumPy array and normalize pixel values
    image_array = np.array(image) / 255.0

    # Extract the age from the filename and convert it to an integer
    age = int(filename.split('_')[0])

    # Append the preprocessed image and label to the lists
    preprocessed_images.append(image_array)
    labels.append(age)

# Convert the lists to NumPy arrays
preprocessed_images = np.array(preprocessed_images)
labels = np.array(labels)

print("Shape of preprocessed images:", preprocessed_images.shape)
print("Shape of labels:", labels.shape)

from sklearn.model_selection import train_test_split

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(preprocessed_images, labels, test_size=0.15, random_state=42)

X_train_normalized = X_train / 255.0
X_test_normalized = X_test / 255.0

from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Dropout

# Define the model architecture with batch normalization
model = Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(256, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
    layers.Dense(256, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
    layers.Dense(128, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
    layers.Dense(1)
])

# Compile the model
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Display the model summary
model.summary()

# Define the number of epochs and batch size
epochs = 40
batch_size = 32

# Train the model
history = model.fit(preprocessed_images, labels, epochs=epochs, batch_size=batch_size, validation_split=0.2)

# Evaluate the model on the test dataset
test_loss, test_accuracy = model.evaluate(test_images, test_labels)

print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)