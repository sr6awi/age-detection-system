# -*- coding: utf-8 -*-
"""Customer_churn using ANN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r1zFZMU-iCIgKdTEPtCsuX_f0d7i6C74
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
from matplotlib import pyplot as plt
import numpy as np
# %matplotlib inline

df = pd.read_csv("customer_churn.csv")
df.sample(5)

df.drop('customerID',axis='columns',inplace=True)
df.dtypes

df.TotalCharges.values

df.MonthlyCharges.values

pd.to_numeric(df.TotalCharges,errors='coerce')

pd.to_numeric(df.TotalCharges,errors='coerce').isnull()

df[pd.to_numeric(df.TotalCharges,errors='coerce').isnull()]
# this dataframe will show u the null values in the TotalCharges

df[pd.to_numeric(df.TotalCharges,errors='coerce').isnull()].shape
# so 11 rows are null

df.iloc[488]['TotalCharges'] # as we can see the row 488 is null ' '

df1  = df[df.TotalCharges!=' ']
df1.shape

df1.TotalCharges = pd.to_numeric(df1.TotalCharges)

df1.TotalCharges.dtypes

tenure_churn_no = df1[df1.Churn=='No'].tenure
tenure_churn_yes = df1[df1.Churn=='Yes'].tenure

plt.xlabel("tenure")
plt.ylabel("Number Of Customers")
plt.title("Customer Churn Prediction Visualiztion")

plt.hist([tenure_churn_yes, tenure_churn_no],  color=['green','red'],label=['Churn=Yes','Churn=No'])
plt.legend()

def print_unique_col_values(df):
       for column in df:
            if df[column].dtypes=='object':
                print(f'{column}: {df[column].unique()}')
                # calling this function will be printing unique values for all your categorical columns

print_unique_col_values(df1)

df1.replace('No internet service','No',inplace=True)
df1.replace('No phone service','No',inplace=True)

print_unique_col_values(df1)

yes_no_columns = ['Partner','Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup',
                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']
#as we know machine learning doesnt understand text best way to convert it to 0 and 1
for col in yes_no_columns:
    df1[col].replace({'Yes': 1,'No': 0},inplace=True)

for col in df1:
    print(f'{col}: {df1[col].unique()}')

df1['gender'].replace({'Female':1,'Male':0},inplace=True)

df1.gender.unique()

df2 = pd.get_dummies(data=df1, columns=['InternetService','Contract','PaymentMethod'])
df2.columns

df2.sample(5)

df2.dtypes

cols_to_scale = ['tenure','MonthlyCharges','TotalCharges']

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()  #converting values into range between 0 and 1
df2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])

df2.sample(5) # as we can see the samples are converted into range between 0s and 1s

for col in df2:
    print(f'{col}: {df2[col].unique()}')

# now my data frame is ready to be used

X = df2.drop('Churn',axis='columns')
y = df2['Churn']

from sklearn.model_selection import train_test_split # spliting our dataset into train and test samples
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)
# we used 80% as train and 20% as a test samples

X_train.shape

X_test.shape

len(X_train.columns) # 26 columns as a training and 1 column was dropped

import tensorflow as tf
from tensorflow import keras

model = keras.Sequential([
    keras.layers.Dense(20,input_shape =(26,),activation='relu'),
    # keras.layer.Dense(15,activation='relu'), no need for a one more dense layer since we have 1 inpurt layer and there as 1 hidden layer and an output layer
    keras.layers.Dense(1,activation='sigmoid'),

])
model.compile(optimizer='adam', # learning rate of adam is 0.01
              loss='binary_crossentropy', # beacuse our output is binary 0 and 1
              metrics=['accuracy'])

model.fit(X_train, y_train, epochs=100)

model.evaluate(X_test,y_test)

yp = model.predict(X_test)
yp[:5]

y_test[:5]

y_pred = []
for element in yp:
    if element > 0.5:
        y_pred.append(1)
    else:
        y_pred.append(0)

y_pred[:5]

from sklearn.metrics import confusion_matrix , classification_report

print(classification_report(y_test,y_pred))

import seaborn as sn
cm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)

plt.figure(figsize = (10,7))
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

#879 + 223 our model got it correct
#185 + 120 our model got an error

round((879+223)/(879+223+185+120),2) # Accuracy is 0.78

round(879/(879+223),2) #Precision for 0 class

round(223/(223+120),2) #precison for 1 class

round(879/(879+120),2) # recall for 0 class

round(223/(223+185),2) # recall for 1 class

