# -*- coding: utf-8 -*-
"""image classification using CNN(cifar100).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q9fVvNZkIyUphffRrXmBwCd9aBCEUd8k
"""

import tensorflow as tf
from tensorflow.keras import datasets,layers,models
import matplotlib.pyplot as plt
import numpy as np

(X_train,y_train),(X_test,y_test) = datasets.cifar10.load_data()
X_train.shape
# 500000 train samples size of 32x32 and 3 color chanels

X_test.shape

plt.figure(figsize=(15,2))
plt.imshow(X_train[4])

y_train.shape

y_train[:5]
# first five samples index 6 , index 9 ...

y_train = y_train.reshape(-1,)
y_train[:5]

classes = ["airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck"]

classes[6]

def plot_sample(X, y, index):
    plt.figure(figsize = (15,2))
    plt.imshow(X[index])
    plt.xlabel(classes[y[index]])

plot_sample(X_train,y_train,0)

plot_sample(X_train,y_train,9)

plot_sample(X_train,y_train,10)

plot_sample(X_train,y_train,55)

X_train[0]/255
# normilzing the image pixels by dividing the image pixels by 255 to be a range (0 & 1)

X_train = X_train / 255
X_test = X_test / 255

ann = models.Sequential([
        layers.Flatten(input_shape=(32,32,3)),
        layers.Dense(3000, activation='relu'),
        layers.Dense(1000, activation='relu'),
        layers.Dense(10, activation='sigmoid')
    ])

ann.compile(optimizer='SGD',
              loss='sparse_categorical_crossentropy', # whenever our y is directly a value then sparse is the best to choose but if its one hot encoded we will use "categorical"
              metrics=['accuracy'])

ann.fit(X_train, y_train, epochs=5)

ann.evaluate(X_test,y_test)

from sklearn.metrics import confusion_matrix , classification_report
import numpy as np
y_pred = ann.predict(X_test)
y_pred_classes = [np.argmax(element) for element in y_pred]

print("Classification Report: \n", classification_report(y_test, y_pred_classes))

cnn = models.Sequential([
         #CNN
         layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(32,32,3)), # --> detecting the features in the images
         layers.MaxPooling2D((2,2)),

         layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu'), # --> detecting the features in the images
         layers.MaxPooling2D((2,2)),

         #dense
        layers.Flatten(),
        layers.Dense(64, activation='relu'),
        layers.Dense(10, activation='relu'),
        layers.Dense(10, activation='softmax')
    ])

cnn.compile(optimizer = 'adam',
              loss = 'sparse_categorical_crossentropy',
              metrics = ['accuracy'])

cnn.fit(X_train,y_train,epochs=10)

cnn.evaluate(X_test,y_test)

y_test = y_test.reshape(-1,)
y_test[:5]
# converting the matrix into 1D of the first matrix we will use (-1,) since the y_test is a 2D array 1D is good enough for our classification

plot_sample(X_test,y_test,3)

y_predict = cnn.predict(X_test)
y_predict[:5]

np.argmax([5,12,1,2])

y_classes = [np.argmax(element) for element in y_pred]
y_classes[:5]

y_test[:5]

plot_sample(X_test,y_test,2)

classes

classes[y_classes[2]]
# as we can since our classes array of the first 5 samples [3, 8, 8, 8, 4]
# and when i tried the test first 5 samples [3, 8, 8, 0, 6] we got 3 correct predictions since our model got around 70% accuracy

